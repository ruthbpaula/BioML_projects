{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9683562e-3713-4259-af71-2cc7dc04b613",
   "metadata": {},
   "source": [
    "# Mock pipeline for brain imaging data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c830ab9-8cb3-4626-bd7c-5d386ceefeb6",
   "metadata": {},
   "source": [
    "Creating a mock pipeline for brain imaging data analysis in Python can be a great way to conceptualize how various steps in such a pipeline might be implemented. Hereâ€™s an outline of a simple pipeline that could be used for analyzing MRI or fMRI data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f8515-c495-4e0f-ab59-c9ccfb84da2c",
   "metadata": {},
   "source": [
    "# 1. Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "558f5d49-a656-4d33-98b2-4dcddc316f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade nibabel\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "def load_brain_image(file_path):\n",
    "    # Load the MRI/fMRI data\n",
    "    img = nib.load(file_path)\n",
    "    data = img.get_fdata()\n",
    "    return data, img.affine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf8abc-1b61-4de4-a515-b60692f4235d",
   "metadata": {},
   "source": [
    "# 2. Preprocessing\n",
    "Description: Perform preprocessing steps such as motion correction, normalization, and skull stripping.\n",
    "Tools: nilearn, fmriprep (if using real data), scipy, sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2f8843d-14bd-4614-bb73-c11d22d56b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nilearn\n",
    "# !pip install --upgrade numpy pandas\n",
    "# !pip uninstall pandas nilearn numexpr bottleneck\n",
    "# !pip install pandas nilearn numexpr bottleneck\n",
    "\n",
    "from nilearn.image import smooth_img, resample_to_img\n",
    "\n",
    "def preprocess_image(data, affine):\n",
    "    # Example of spatial smoothing\n",
    "    smoothed_img = smooth_img(nib.Nifti1Image(data, affine), fwhm=6)\n",
    "    return smoothed_img.get_fdata(), smoothed_img.affine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6633a2-2fb4-4612-b397-8e7cdebd17e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Feature Extraction\n",
    "Description: Extract features from the brain imaging data, such as time series, voxel intensities, or regional averages.\n",
    "Tools: nilearn, scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad65ac7-7084-4b1d-b683-0eff3a14e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "def extract_features(data, affine, mask_img):\n",
    "    masker = NiftiMasker(mask_img=mask_img)\n",
    "    time_series = masker.fit_transform(nib.Nifti1Image(data, affine))\n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d893fc-0ee9-43bf-9fc3-a00f47861893",
   "metadata": {},
   "source": [
    "# 4. Analysis\n",
    "Description: Perform statistical analysis, such as voxel-based morphometry (VBM), region of interest (ROI) analysis, or machine learning classification.\n",
    "Tools: nilearn, scikit-learn, statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3afd369-ca04-489a-9138-b1e3e42dd249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def perform_analysis(time_series):\n",
    "    # Example: Dimensionality reduction using PCA\n",
    "    pca = PCA(n_components=10)\n",
    "    reduced_data = pca.fit_transform(time_series)\n",
    "\n",
    "    # Example: Clustering brain regions\n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    clusters = kmeans.fit_predict(reduced_data)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d9375-a11f-416e-bad8-6531c883af6d",
   "metadata": {},
   "source": [
    "# 5. Visualization\n",
    "Description: Visualize the results, such as displaying brain slices, plotting activation maps, or showing clusters.\n",
    "Tools: matplotlib, nilearn.plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4a34b76-6654-4dc0-aaf2-6ab58bb93708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade matplotlib\n",
    "# !pip install --upgrade nilearn\n",
    "# !pip install numpy<2\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from nilearn import plotting\n",
    "\n",
    "def visualize_results(data, affine, clusters):\n",
    "    # Plotting brain slices\n",
    "    plotting.plot_stat_map(nib.Nifti1Image(clusters, affine), threshold=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bdb1b-7fa6-43c2-a018-7135c631e745",
   "metadata": {},
   "source": [
    "# 6. Reporting\n",
    "Description: Generate reports with the key findings, including visualizations and statistical summaries.\n",
    "Tools: reportlab, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34f45fa6-ecc9-4b21-ada1-c0c21e12ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install reportlab\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "def generate_report(output_path, summary_text):\n",
    "    c = canvas.Canvas(output_path, pagesize=letter)\n",
    "    c.drawString(100, 750, summary_text)\n",
    "    c.showPage()\n",
    "    c.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1876a6d-c1da-4db4-8790-9561d49c69c1",
   "metadata": {},
   "source": [
    "# 7. Run all steps together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1549502e-89e3-470c-acc9-02f7b6f77456",
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionError",
     "evalue": "Input data has incompatible dimensionality: Expected dimension is 3D and you provided a 4D image. See https://nilearn.github.io/stable/manipulating_images/input_output.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDimensionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25668/4156124203.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Step 3: Extract Features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtime_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0matlas_filename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# path_to_mask.nii ; having issues with cort-prob-2mm mask bc it's 4d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Step 4: Analyze Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25668/1291014783.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(data, affine, mask_img)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmasker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNiftiMasker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtime_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNifti1Image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtime_series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nilearn\\maskers\\base_masker.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, confounds, sample_mask, **fit_params)\u001b[0m\n\u001b[0;32m    308\u001b[0m                 )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m             return self.fit(**fit_params).transform(\n\u001b[0m\u001b[0;32m    311\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nilearn\\maskers\\nifti_masker.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, imgs, y)\u001b[0m\n\u001b[0;32m    446\u001b[0m             )\n\u001b[0;32m    447\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_img_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreports\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# save inputs for reporting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nilearn\\_utils\\niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[1;34m(niimg, dtype)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \"\"\"\n\u001b[1;32m--> 370\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nilearn\\_utils\\niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[1;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mDimensionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_iterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDimensionError\u001b[0m: Input data has incompatible dimensionality: Expected dimension is 3D and you provided a 4D image. See https://nilearn.github.io/stable/manipulating_images/input_output.html."
     ]
    }
   ],
   "source": [
    "# Step 0: Download sample brain image and brain mask\n",
    "import numpy as np\n",
    "from nilearn import datasets\n",
    "\n",
    "fmri_img = datasets.fetch_development_fmri(n_subjects=1)['func'][0]\n",
    "\n",
    "# Fetch the Harvard-Oxford atlas, which includes masks\n",
    "atlas_data = datasets.fetch_atlas_harvard_oxford('cort-prob-2mm')\n",
    "atlas_filename = atlas_data['filename']\n",
    "\n",
    "# Step 1: Load Data\n",
    "data, affine = load_brain_image(fmri_img) # path_to_brain_image.nii\n",
    "\n",
    "# Step 2: Preprocess Data\n",
    "preprocessed_data, affine = preprocess_image(data, affine)\n",
    "\n",
    "# Step 3: Extract Features\n",
    "time_series = extract_features(preprocessed_data, affine, mask_img=atlas_filename) # path_to_mask.nii ; having issues with cort-prob-2mm mask bc it's 4d\n",
    "\n",
    "# Step 4: Analyze Data\n",
    "clusters = perform_analysis(time_series)\n",
    "\n",
    "# Step 5: Visualize Results\n",
    "visualize_results(preprocessed_data, affine, clusters)\n",
    "\n",
    "# Step 6: Generate Report\n",
    "generate_report('brain_analysis_report.pdf', \"Summary of brain analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e291bee-4b2d-4c19-83d8-c37383725b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
